# ğŸ§  Self-Organizing Map (SOM)

**Text Clustering using SOM**

Text clustering is an unsupervised process used to separate a document collection into clusters based on the similarity relationships between documents. Let ğ· = {ğ‘‘1, â€¦ , ğ‘‘ğ‘} represent a collection of ğ‘ documents to be clustered. The task was to divide ğ· into ğ‘˜ clusters ğ¶1, â€¦ , ğ¶ğ‘˜ such that ğ¶1 âˆª â€¦ âˆª ğ¶ğ‘˜ = ğ· and ğ¶ğ‘– âˆ© ğ¶ğ‘— = âˆ… for ğ‘– â‰  ğ‘—.

SOM-based text clustering was performed in two main phases:  
- The first phase involved document preprocessing, using the Vector Space Model (VSM) to generate numeric vectors for each text document.  
- In the second phase, SOM was applied on these document vectors to obtain the clusters.

---

## ğŸ—ƒï¸ Dataset

The project utilized the BBC news dataset, which contains 2,225 news documents categorized into five classes:  
**business**, **entertainment**, **politics**, **sport**, and **tech**. The dataset covers stories from 2004 to 2005.

---

## ğŸ” Phase 1: Document Preprocessing

Using VSM, each document ğ‘‘ğ‘– was represented as an ğ‘›-dimensional feature vector  
ğ’—ğ‘– = < ğ‘£ğ‘–1, â€¦ , ğ‘£ğ‘–ğ‘› >,  
where ğ‘£ğ‘–ğ‘— indicates the weight of term ğ‘¡ğ‘— in document ğ‘‘ğ‘–, and ğ‘› is the total number of distinct terms in the document collection ğ·.

The weights ğ‘£ğ‘–ğ‘— were computed using the Term Frequency - Inverse Document Frequency (TF-IDF) weighting scheme as follows:

<p align="center">
  <img src="https://user-images.githubusercontent.com/91370511/159134697-02c91891-bf44-47a4-97dc-c3ea5f097b42.PNG" alt="TF-IDF formula" />
</p>

where:  
- ğ‘¡ğ‘“ğ‘–ğ‘— is the frequency of term ğ‘¡ğ‘— in document ğ‘‘ğ‘–  
- ğ‘‘ğ‘“ğ‘— is the number of documents in ğ· containing term ğ‘¡ğ‘—  

Preprocessing steps applied to each document included:  
1. Removal of all non-letter characters  
2. Extraction of words and removal of short words with length less than or equal to 2  
3. Removal of stop words, as specified in the provided `stopwords.txt` file  
4. Computation of feature vectors using the TF-IDF weighting scheme

---

## ğŸ§© Phase 2: SOM Clustering

### a) Winner-takes-all Approach  
- An SOM was built using all documents with one neuron assigned per class  
- The SOM hits plot was depicted  
- The confusion matrix was computed and reported to evaluate classification performance

### b) On-center, Off-surround Approach  
- SOMs were constructed with 3Ã—3 neurons using the entire dataset  
- The SOM hits plot was visualized  
- The Euclidean distances between all documents and their respective winner neurons were calculated and summed  
- The process was repeated for SOM topologies of sizes 4Ã—4 and 5Ã—5  
